\section{Обучающие алгоритмы}

\subsection*{Линейная регрессия} 
\indent \indent Линейная регрессия ~--- используемая в статистике регрессионная модель зависимости одной переменной $y$ от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) $x$ с линейной функцией зависимости. Линейная регрессия бывает двух типов: простая линейная регрессия и множественная линейная регрессия. Простая линейная регрессия характеризуется одной независимой переменной. Множественная линейная регрессия характеризуется множеством независимых переменных.

\subsection*{Логистическая регрессия} 
\indent \indent Логистическая регрессия ~--- это статистическая модель, используемая для прогнозирования вероятности возникновения некоторого события путём подгонки данных к логистической кривой. Он используется для оценки дискретных значений (двоичные значения, такие как 0/1, да/нет, истина/ложь) на основе заданного набора независимых переменных. Этот алгоритм предсказывает вероятность возникновения события путем подгонки данных к функции logit. Следовательно, это также известно как регрессия логита. Поскольку он предсказывает вероятность, его выходные значения лежат между 0 и 1.

\subsection*{Наивная байесовская классификация}
\indent \indent Наивная байесовская классификация ~--- Это метод классификации, основанный на  теореме Байеса с предположением независимости между предикторами. Наивный байесовский классификатор предполагает, что наличие определенной функции в классе не связано с наличием любой другой функции. Байесовский подход к классификации основан на теореме, утверждающей, что если плотности распределения каждого из классов известны, то искомый алгоритм можно выписать в явном аналитическом виде. Более того, этот алгоритм оптимален, то есть обладает минимальной вероятностью ошибок.
