\subsection{Квадратичная целевая функция}

$$ \mathlarger{ J = \frac{1}{2} \sum_{i=1}^{n} (\hat{y}^{(i)} - y^{(i)}})^2 \eqno(2)$$ \\
Где $n$ - количество примеров на обучающей выборке \\
$\hat{y}^{(i)} = \sigma (w^T x^{(i)})$ - предсказанное моделью значение \\
$y^{(i)}$ - реальное значение целевой переменной на конкретном примере

Функцией потерь в данном случаю будет выражение $(\hat{y}^{(i)} - y^{(i)})^2$ . В зарубежной литературе функция потерь пишется как \textit{loss function} или \textit{cost function}.
Данная функция была выбрана потому что она проста и понятна. В дальнейшем удобство функции будет заметно при нахождении частных производных. Если взглянуть на функцию внимательно, можно заметить что она зависит от двух аргументов: с одной стороны от данных($\hat{y}^{(i)}$), c другой стороны от параметров модели($y^{(i)}$). Данные - это то, что фиксировано, а параметры - то, что будет меняться. Задача заключается в подборке таких параметров, на которых модель будет хорошо работать.

Целевая функция показывает на сколько сильно модель ошибалась. Чем меньше модель ошибается, тем лучше она справляется со своей задачей. Значит необходимо уменьшить эту ошибку. Для уменьшения ошибки хорошо подходит градиент, показывающий направление наибольшего роста функции. А значит отрицание градиента будет показывать нискорейшее убывание функции.

Данное понимание градиента можно применить к обучению линейного нейрона. Один шаг алгоритма будет уменьшать веса модели: $$w_{j+1} = w_j - \alpha \nabla J \eqno(3)$$

В данной формуле $w_j$ - это текущий вес, $\alpha$ - коэффициент обучения(\textit{learning rate}), а $\nabla J$ - градиент целевой функции.
Этот шаг продолжается до тех пор, пока веса не перестанут меняться(\textit{с какой-то точностью}), либо пока количество итераций не достигнет заданного максимума.

Дальнейшие вычисления удобно вести в матричном и векторном виде. Для такого же удобного использования выведенных формул будет использоваться библиотека NumPy для языка Python.