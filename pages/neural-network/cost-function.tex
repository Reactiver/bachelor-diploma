\subsection{Квадратичная целевая функция}
\indent \indent Квадратичная целевая функция — это квадратичная функция нескольких переменных, подлежащая оптимизации (минимизации или максимизации) в целях решения некоторой оптимизационной задачи. Данная функция выглядит следующим образом: 

$$ \mathlarger{ J = \frac{1}{2} \sum_{i=1}^{n} (\hat{y}^{(i)} - y^{(i)}})^2 ,\eqno(2)$$ \\
где $n$ - количество примеров на обучающей выборке; \\
$\hat{y}^{(i)} = \sigma (w^T x^{(i)})$ - предсказанное моделью значение; \\
$y^{(i)}$ - реальное значение целевой переменной на конкретном примере.

Функцией потерь в данном случаю будет выражение $(\hat{y}^{(i)} - y^{(i)})^2$ . В зарубежной литературе функция потерь пишется как \textit{loss function} или \textit{cost function}. В дальнейшем удобство функции будет заметно при нахождении частных производных. Можно заметить, что функция зависит от двух аргументов: с одной стороны от данных($\hat{y}^{(i)}$), c другой стороны от параметров модели($y^{(i)}$). Данные - это то, что фиксировано, а параметры - то, что будет меняться. Задача заключается в подборке таких параметров, на которых модель будет хорошо работать.

Целевая функция показывает на сколько сильно модель ошибалась. Чем меньше модель ошибается, тем лучше она справляется со своей задачей. Значит необходимо уменьшить эту ошибку. Для уменьшения ошибки хорошо подходит градиент, показывающий направление наибольшего роста функции. А значит отрицание градиента будет показывать нискорейшее убывание функции.

Данное понимание градиента можно применить к обучению линейного нейрона. Один шаг алгоритма будет уменьшать веса модели: $$w_{j+1} = w_j - \alpha \nabla J \eqno(3)$$

В данной формуле $w_j$ - это текущий вес, $\alpha$ - коэффициент обучения(\textit{learning rate}), а $\nabla J$ - градиент целевой функции.
Этот шаг продолжается до тех пор, пока веса не перестанут меняться(с какой-то точностью), либо пока количество итераций не достигнет заданного максимума.